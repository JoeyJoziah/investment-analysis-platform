apiVersion: 1
groups:
  - name: investment-analysis-alerts
    interval: 1m
    rules:
      # Cost Monitoring Alerts
      - uid: cost-warning
        title: Monthly Cost Warning
        condition: cost_threshold
        data:
          - refId: A
            relativeTimeRange:
              from: 86400
              to: 0
            datasourceUid: prometheus
            model:
              expr: monthly_cost_estimate
              refId: A
        noDataState: NoData
        execErrState: Alerting
        for: 5m
        annotations:
          description: "Monthly cost estimate is approaching budget limit: ${{ $value }}"
          runbook_url: "https://docs.example.com/runbooks/cost-optimization"
          summary: "Cost warning: {{ $value }}% of $50 budget used"
        labels:
          severity: warning
          team: platform
          
      - uid: cost-critical
        title: Monthly Cost Critical
        condition: cost_critical
        data:
          - refId: A
            relativeTimeRange:
              from: 86400
              to: 0
            datasourceUid: prometheus
            model:
              expr: monthly_cost_estimate > 45
              refId: A
        noDataState: NoData
        execErrState: Alerting
        for: 1m
        annotations:
          description: "CRITICAL: Monthly costs exceeding 90% of budget!"
          summary: "Cost CRITICAL: ${{ $value }} of $50 budget"
        labels:
          severity: critical
          team: platform
          
      # API Rate Limit Alerts
      - uid: api-rate-limit-warning
        title: API Rate Limit Warning
        condition: rate_limit_warning
        data:
          - refId: A
            datasourceUid: prometheus
            model:
              expr: |
                (api_calls_total{provider="alpha_vantage"} / 25) > 0.8 or
                (api_calls_total{provider="polygon"} / 7200) > 0.8
              refId: A
        for: 5m
        annotations:
          description: "API provider {{ $labels.provider }} approaching rate limit"
          summary: "{{ $labels.provider }} at {{ $value }}% of limit"
        labels:
          severity: warning
          
      # Model Performance Alerts
      - uid: model-accuracy-degradation
        title: Model Accuracy Degradation
        condition: accuracy_threshold
        data:
          - refId: A
            datasourceUid: prometheus
            model:
              expr: model_accuracy_score < 0.6
              refId: A
        for: 15m
        annotations:
          description: "ML model accuracy has dropped below threshold: {{ $value }}"
          summary: "Model performance degradation detected"
        labels:
          severity: warning
          team: ml
          
      # System Health Alerts
      - uid: high-response-time
        title: High API Response Time
        condition: response_time
        data:
          - refId: A
            datasourceUid: prometheus
            model:
              expr: |
                histogram_quantile(0.95, 
                  rate(http_request_duration_seconds_bucket[5m])
                ) > 2
              refId: A
        for: 5m
        annotations:
          description: "95th percentile response time exceeding 2 seconds"
          summary: "High API latency detected: {{ $value }}s"
        labels:
          severity: warning
          
      - uid: database-connection-failure
        title: Database Connection Failure
        condition: db_connection
        data:
          - refId: A
            datasourceUid: prometheus
            model:
              expr: up{job="postgres"} == 0
              refId: A
        for: 1m
        annotations:
          description: "PostgreSQL database is not responding"
          summary: "Database connection failure"
        labels:
          severity: critical
          team: platform
          
      - uid: redis-cache-failure
        title: Redis Cache Failure
        condition: redis_health
        data:
          - refId: A
            datasourceUid: prometheus
            model:
              expr: up{job="redis"} == 0
              refId: A
        for: 1m
        annotations:
          description: "Redis cache is not responding"
          summary: "Cache service failure"
        labels:
          severity: critical
          
      # Business Metric Alerts
      - uid: low-recommendation-generation
        title: Low Recommendation Generation
        condition: recommendations_count
        data:
          - refId: A
            datasourceUid: prometheus
            model:
              expr: |
                increase(recommendations_generated_total[1h]) < 10
              refId: A
        for: 30m
        annotations:
          description: "Recommendation generation rate is unusually low"
          summary: "Only {{ $value }} recommendations in last hour"
        labels:
          severity: warning
          team: ml
          
      - uid: no-stocks-analyzed
        title: No Stocks Analyzed
        condition: stock_analysis
        data:
          - refId: A
            datasourceUid: prometheus
            model:
              expr: |
                increase(stocks_analyzed_total[6h]) == 0
              refId: A
        for: 10m
        annotations:
          description: "No stocks have been analyzed in the last 6 hours"
          summary: "Stock analysis pipeline may be stuck"
        labels:
          severity: critical
          team: data

# Notification policies
notification_policies:
  - uid: default-policy
    receiver: slack-default
    group_by: [alertname, severity]
    group_interval: 5m
    repeat_interval: 12h
    
  - uid: critical-policy
    receiver: pagerduty-critical
    matchers:
      - severity = critical
    group_interval: 1m
    repeat_interval: 1h
    
  - uid: cost-policy
    receiver: email-finance
    matchers:
      - alertname =~ ".*cost.*"
    group_interval: 30m
    repeat_interval: 24h

# Contact points (configure in Grafana UI)
contact_points:
  - uid: slack-default
    name: Slack Default
    type: slack
    settings:
      webhook_url: "${SLACK_WEBHOOK_URL}"
      title: "Investment Platform Alert"
      
  - uid: email-finance
    name: Finance Team Email
    type: email
    settings:
      addresses: "finance@example.com"
      
  - uid: pagerduty-critical
    name: PagerDuty Critical
    type: pagerduty
    settings:
      integration_key: "${PAGERDUTY_KEY}"