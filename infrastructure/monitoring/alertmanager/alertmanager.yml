# Alertmanager configuration for Investment Analysis Application
global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@investment-analysis.com'
  smtp_auth_username: ''
  smtp_auth_password: ''
  slack_api_url: ''

# Templates
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Alert routing tree
route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 12h
  receiver: 'default-receiver'
  
  routes:
    # Critical alerts - immediate notification
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 10s
      group_interval: 1m
      repeat_interval: 30m
      
    # Budget alerts - special handling
    - match_re:
        alertname: '^(BudgetExceeded|CostSpike|APIQuotaExceeded)$'
      receiver: 'budget-alerts'
      group_wait: 15s
      group_interval: 2m
      repeat_interval: 1h
      
    # Security alerts - immediate notification
    - match_re:
        alertname: '^(SecurityIncident|AuthenticationFailures|SuspiciousActivity)$'
      receiver: 'security-alerts'
      group_wait: 5s
      group_interval: 30s
      repeat_interval: 15m
      
    # Data quality alerts
    - match_re:
        alertname: '^(DataQualityDegraded|DataStale|ValidationFailed)$'
      receiver: 'data-quality-alerts'
      group_wait: 2m
      group_interval: 10m
      repeat_interval: 2h
      
    # Performance alerts
    - match_re:
        alertname: '^(HighLatency|ErrorRateHigh|ServiceDown)$'
      receiver: 'performance-alerts'
      group_wait: 1m
      group_interval: 5m
      repeat_interval: 1h
      
    # Maintenance mode - suppress non-critical alerts
    - match:
        maintenance: 'true'
      receiver: 'null'

# Inhibition rules - suppress certain alerts when others fire
inhibit_rules:
  # Suppress individual service alerts when cluster is down
  - source_match:
      alertname: 'ClusterDown'
    target_match_re:
      alertname: '^(ServiceDown|HighLatency|ErrorRateHigh)$'
    equal: ['cluster']

  # Suppress high latency alerts when service is down
  - source_match:
      alertname: 'ServiceDown'
    target_match:
      alertname: 'HighLatency'
    equal: ['service', 'instance']

  # Suppress data quality alerts when data ingestion is down
  - source_match:
      alertname: 'DataIngestionDown'
    target_match_re:
      alertname: '^(DataQualityDegraded|DataStale)$'
    equal: ['service']

# Receiver configurations
receivers:
  # Default receiver (low priority alerts)
  - name: 'default-receiver'
    email_configs:
      - to: 'dev-team@investment-analysis.com'
        subject: '[Investment Analysis] {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          
          Details:
          {{ range .Labels.SortedPairs }}  {{ .Name }}: {{ .Value }}
          {{ end }}
          
          Graph: {{ .GeneratorURL }}
          Silence: {{ .SilenceURL }}
          {{ end }}
        html: |
          <!DOCTYPE html>
          <html>
          <head>
            <meta charset="UTF-8">
            <title>Investment Analysis Alert</title>
          </head>
          <body>
            <h2 style="color: #ff9800;">Investment Analysis Alert</h2>
            {{ range .Alerts }}
            <div style="background-color: #f5f5f5; padding: 10px; margin: 10px 0; border-left: 4px solid #ff9800;">
              <h3>{{ .Annotations.summary }}</h3>
              <p><strong>Description:</strong> {{ .Annotations.description }}</p>
              <p><strong>Severity:</strong> {{ .Labels.severity }}</p>
              <p><strong>Service:</strong> {{ .Labels.service }}</p>
              <p><strong>Instance:</strong> {{ .Labels.instance }}</p>
              <p><strong>Started:</strong> {{ .StartsAt }}</p>
              <p><a href="{{ .GeneratorURL }}">View Graph</a> | <a href="{{ .SilenceURL }}">Silence Alert</a></p>
            </div>
            {{ end }}
          </body>
          </html>

  # Critical alerts - multiple channels
  - name: 'critical-alerts'
    email_configs:
      - to: 'oncall@investment-analysis.com'
        subject: '[CRITICAL] Investment Analysis Alert'
        body: |
          ðŸš¨ CRITICAL ALERT ðŸš¨
          
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Service: {{ .Labels.service }}
          Instance: {{ .Labels.instance }}
          Started: {{ .StartsAt }}
          
          Runbook: {{ .Annotations.runbook_url }}
          Graph: {{ .GeneratorURL }}
          {{ end }}
          
          This is a critical alert requiring immediate attention.
    
    slack_configs:
      - api_url: '{{ .SlackAPIURL }}'
        channel: '#critical-alerts'
        title: 'ðŸš¨ Critical Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Service:* {{ .Labels.service }}
          *Summary:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Started:* {{ .StartsAt }}
          {{ if .Annotations.runbook_url }}*Runbook:* {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        actions:
          - type: button
            text: 'View Grafana Dashboard'
            url: 'http://grafana:3001/d/investment-system-health'
          - type: button
            text: 'Silence Alert'
            url: '{{ .SilenceURL }}'

  # Budget alerts - financial team notification
  - name: 'budget-alerts'
    email_configs:
      - to: 'finance@investment-analysis.com,dev-team@investment-analysis.com'
        subject: '[BUDGET ALERT] Investment Analysis - {{ .GroupLabels.alertname }}'
        body: |
          ðŸ’° BUDGET ALERT ðŸ’°
          
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          
          Current Cost: {{ .Labels.current_cost }}
          Budget Limit: {{ .Labels.budget_limit }}
          Usage Percentage: {{ .Labels.usage_percentage }}%
          
          Started: {{ .StartsAt }}
          {{ end }}
          
          Please review cost optimization strategies.
    
    slack_configs:
      - api_url: '{{ .SlackAPIURL }}'
        channel: '#budget-alerts'
        title: 'ðŸ’° Budget Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Current Cost:* ${{ .Labels.current_cost }}
          *Budget Limit:* ${{ .Labels.budget_limit }}
          *Usage:* {{ .Labels.usage_percentage }}%
          *Description:* {{ .Annotations.description }}
          {{ end }}

  # Security alerts - security team
  - name: 'security-alerts'
    email_configs:
      - to: 'security@investment-analysis.com,oncall@investment-analysis.com'
        subject: '[SECURITY] Investment Analysis Alert'
        body: |
          ðŸ”’ SECURITY ALERT ðŸ”’
          
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          
          Source IP: {{ .Labels.source_ip }}
          User ID: {{ .Labels.user_id }}
          Service: {{ .Labels.service }}
          
          Started: {{ .StartsAt }}
          {{ end }}
          
          This is a security-related alert requiring immediate investigation.

  # Data quality alerts - data team
  - name: 'data-quality-alerts'
    email_configs:
      - to: 'data-team@investment-analysis.com'
        subject: '[DATA QUALITY] Investment Analysis Alert'
        body: |
          ðŸ“Š DATA QUALITY ALERT ðŸ“Š
          
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          
          Data Type: {{ .Labels.data_type }}
          Quality Score: {{ .Labels.quality_score }}
          Provider: {{ .Labels.provider }}
          
          Started: {{ .StartsAt }}
          {{ end }}

  # Performance alerts - dev team
  - name: 'performance-alerts'
    email_configs:
      - to: 'dev-team@investment-analysis.com'
        subject: '[PERFORMANCE] Investment Analysis Alert'
        body: |
          âš¡ PERFORMANCE ALERT âš¡
          
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          
          Service: {{ .Labels.service }}
          Instance: {{ .Labels.instance }}
          Current Value: {{ .Labels.value }}
          Threshold: {{ .Labels.threshold }}
          
          Started: {{ .StartsAt }}
          Graph: {{ .GeneratorURL }}
          {{ end }}

  # Null receiver for maintenance mode
  - name: 'null'