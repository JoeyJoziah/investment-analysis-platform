# ============================================================================
# AIRFLOW-SPECIFIC ENVIRONMENT VARIABLES
# ============================================================================
# This file contains Airflow-specific variables that complement the main .env file
# Use this file specifically for Docker Compose Airflow deployment
# ============================================================================

# ============================================================================
# AIRFLOW CORE CONFIGURATION
# ============================================================================
# Fernet key for encrypting connection passwords, variables, and configurations
AIRFLOW_FERNET_KEY=DpuJvXHWimMqS03BWRG9-wBlcmg6q7xsMINwyaYeUWo=

# Secret key for Flask sessions and CSRF protection
AIRFLOW_SECRET_KEY=4b2c6743542bdb84e0be01d9a9b582ed6ec71b53123bad70eb0f6ce508c14cf8

# ============================================================================
# AIRFLOW SMTP CONFIGURATION (Email Notifications)
# ============================================================================
# Leave empty to disable email notifications
SMTP_USER=
SMTP_PASSWORD=
SMTP_FROM=noreply@investment-app.com

# ============================================================================
# AIRFLOW FLOWER MONITORING
# ============================================================================
# Password for Flower monitoring interface (admin:password format in docker-compose)
FLOWER_PASSWORD=secure_flower_password_123

# ============================================================================
# AIRFLOW DATABASE CONFIGURATION
# ============================================================================
# Database connection details for Airflow metadata
AIRFLOW_DB_HOST=postgres
AIRFLOW_DB_PORT=5432
AIRFLOW_DB_NAME=airflow_db
AIRFLOW_DB_USER=airflow_user
AIRFLOW_DB_PASSWORD=secure_airflow_db_password_456

# ============================================================================
# AIRFLOW WEB USER CONFIGURATION
# ============================================================================
# Default admin user for Airflow web interface
_AIRFLOW_WWW_USER_USERNAME=admin
_AIRFLOW_WWW_USER_PASSWORD=secure_admin_password_789

# ============================================================================
# AIRFLOW UID/GID CONFIGURATION
# ============================================================================
# User ID for Airflow processes (important for file permissions)
AIRFLOW_UID=50000
AIRFLOW_GID=0

# ============================================================================
# DOCKER PROJECT DIRECTORY
# ============================================================================
# Project directory for volume mounts
AIRFLOW_PROJ_DIR=.

# ============================================================================
# AIRFLOW PERFORMANCE TUNING
# ============================================================================
# Executor configuration
AIRFLOW__CORE__EXECUTOR=CeleryExecutor

# Parallelism settings
AIRFLOW__CORE__PARALLELISM=32
AIRFLOW__CORE__DAG_CONCURRENCY=16
AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG=1
AIRFLOW__CORE__MAX_ACTIVE_TASKS_PER_DAG=16

# Worker configuration
AIRFLOW__CELERY__WORKER_CONCURRENCY=4

# ============================================================================
# AIRFLOW SECURITY SETTINGS
# ============================================================================
# Authentication backend
AIRFLOW__WEBSERVER__AUTH_BACKEND=airflow.contrib.auth.backends.password_auth
AIRFLOW__WEBSERVER__AUTHENTICATE=true
AIRFLOW__WEBSERVER__RBAC=true
AIRFLOW__WEBSERVER__EXPOSE_CONFIG=false

# API configuration
AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session
AIRFLOW__API__ENABLE_EXPERIMENTAL_API=false

# ============================================================================
# AIRFLOW LOGGING CONFIGURATION
# ============================================================================
AIRFLOW__LOGGING__LOGGING_LEVEL=INFO
AIRFLOW__LOGGING__FAB_LOGGING_LEVEL=WARN
AIRFLOW__LOGGING__COLORED_CONSOLE_LOG=false
AIRFLOW__LOGGING__REMOTE_LOGGING=false

# ============================================================================
# AIRFLOW SCHEDULER CONFIGURATION
# ============================================================================
AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=300
AIRFLOW__SCHEDULER__CATCHUP_BY_DEFAULT=false
AIRFLOW__SCHEDULER__MAX_TIS_PER_QUERY=512
AIRFLOW__SCHEDULER__PROCESSOR_POLL_INTERVAL=1

# ============================================================================
# AIRFLOW DAG CONFIGURATION
# ============================================================================
AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
AIRFLOW__CORE__LOAD_EXAMPLES=false
AIRFLOW__CORE__STORE_SERIALIZED_DAGS=true
AIRFLOW__CORE__STORE_DAG_CODE=true

# ============================================================================
# AIRFLOW POOL CONFIGURATION
# ============================================================================
AIRFLOW__CORE__DEFAULT_POOL_TASK_SLOT_COUNT=128

# ============================================================================
# AIRFLOW EMAIL CONFIGURATION
# ============================================================================
AIRFLOW__EMAIL__EMAIL_BACKEND=airflow.utils.email.send_email_smtp

# ============================================================================
# AIRFLOW FLOWER CONFIGURATION
# ============================================================================
AIRFLOW__CELERY__FLOWER_HOST=0.0.0.0
AIRFLOW__CELERY__FLOWER_PORT=5555

# ============================================================================
# REDIS CONFIGURATION (Airflow-specific database 2)
# ============================================================================
AIRFLOW_REDIS_DB=2

# ============================================================================
# SECURITY NOTES
# ============================================================================
# 1. Change all passwords marked as "secure_*" before production use
# 2. Generate a new AIRFLOW_FERNET_KEY using: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
# 3. Generate a new AIRFLOW_SECRET_KEY using: python -c "import secrets; print(secrets.token_hex(32))"
# 4. Store sensitive variables in a secrets management system for production
# ============================================================================