# Performance Optimizations - Investment Analysis Platform

Based on analysis of Claude Code's development container configuration, the following performance optimizations have been implemented:

## üöÄ Key Optimizations Applied

### 1. **Memory Management**
- **Node.js**: Configured with `--max-old-space-size=4096` to prevent OOM errors during large data processing
- **Python**: Enabled bytecode compilation and optimization flags
- **Docker**: Applied memory limits and reservations for all services

### 2. **Development Container**
- Created `.devcontainer/` configuration for consistent development environment
- Includes performance tools: ripgrep, fd, delta, htop, iotop
- Persistent volume mounts for caches and command history
- Optimized workspace mounting with `consistency=delegated`

### 3. **Command-Line Performance**
- Replaced `grep` with `ripgrep` (10-100x faster for code searches)
- Replaced `find` with `fd` (faster and more intuitive)
- Configured smart aliases and wrappers in `scripts/optimize_performance.sh`

### 4. **Database Optimization**
- PostgreSQL tuned for 2GB RAM with SSD storage
- Enabled parallel query execution
- Configured aggressive autovacuum for consistent performance
- Added query logging for slow queries (>100ms)

### 5. **Caching Strategy**
- Redis configured with LRU eviction and 1GB memory limit
- NPM and pip caches persisted in Docker volumes
- Frontend build cache optimization

### 6. **Docker Performance**
- Created `docker-compose.performance.yml` with resource limits
- Implemented health checks and restart policies
- Used Alpine-based images where possible
- Configured logging rotation to prevent disk fill

## üìä Performance Metrics

### Before Optimization
- File search: ~5-10 seconds for large searches
- Docker memory usage: Unbounded, occasional OOM
- Database queries: No optimization, slow on large datasets
- Build times: 5-10 minutes for full rebuild

### After Optimization (Expected)
- File search: <1 second with ripgrep
- Docker memory usage: Capped at 8GB total
- Database queries: 50-70% faster with proper indexing
- Build times: 2-3 minutes with caching

## üõ†Ô∏è Usage Instructions

### 1. Apply All Optimizations
```bash
# Run the optimization script
./scripts/optimize_performance.sh

# Restart shell to apply changes
exec $SHELL
```

### 2. Use Development Container
```bash
# With VS Code
code . 
# Then: F1 -> "Remote-Containers: Reopen in Container"

# Or with Docker directly
docker-compose -f docker-compose.yml -f docker-compose.performance.yml up
```

### 3. Test Performance
```bash
# Run performance test suite
./test_performance.sh

# Check current performance
perf-check

# Monitor specific metrics
perf-cpu    # Top CPU consumers
perf-mem    # Top memory consumers
perf-docker # Docker resource usage
```

### 4. Search Operations
```bash
# Fast file search (instead of find)
fd "*.py" backend/

# Fast content search (instead of grep)
rg "def analyze" --type py

# Interactive file finder
fzf
```

## üîß Configuration Files

| File | Purpose |
|------|---------|
| `.devcontainer/devcontainer.json` | VS Code dev container configuration |
| `.devcontainer/Dockerfile` | Development environment image |
| `.ripgreprc` | Ripgrep search configuration |
| `docker-compose.performance.yml` | Optimized Docker services |
| `infrastructure/postgres/postgresql.conf` | PostgreSQL performance tuning |

## üìà Monitoring

### Real-time Monitoring
```bash
# System resources
htop

# Disk I/O
iotop

# Docker containers
docker stats

# Database activity
psql -c "SELECT * FROM pg_stat_activity WHERE state != 'idle';"

# Redis stats
redis-cli INFO stats
```

### Performance Profiling
```bash
# Python profiling
py-spy top -- python backend/api/main.py

# Memory profiling
python -m memory_profiler backend/analytics/technical_analysis.py

# Line profiling
kernprof -l -v backend/ml/training_pipeline.py
```

## üéØ Best Practices

1. **Always use ripgrep** for searching code (`rg` command)
2. **Use fd** for finding files (`fd` command)
3. **Monitor resource usage** during heavy operations
4. **Use the dev container** for consistent environment
5. **Run performance tests** after major changes

## üîÑ Continuous Optimization

The performance configuration is designed to be iterative. Monitor these metrics regularly:

- API response times (target: <100ms for simple queries)
- Database query performance (target: <50ms for indexed queries)
- Memory usage (should stay under 80% of limits)
- Cache hit rates (target: >80% for frequently accessed data)

## üêõ Troubleshooting

### High Memory Usage
```bash
# Check memory consumers
ps aux | sort -nrk 4,4 | head -10

# Clear caches if needed
sync && echo 3 | sudo tee /proc/sys/vm/drop_caches
```

### Slow Queries
```bash
# Check slow query log
tail -f data/postgres/pg_log/*.log | grep "duration:"

# Analyze query plan
psql -c "EXPLAIN ANALYZE <your query here>;"
```

### Docker Issues
```bash
# Reset Docker resources
docker system prune -a --volumes

# Rebuild with fresh cache
docker-compose build --no-cache
```

## üìö References

- [Claude Code Repository](https://github.com/anthropics/claude-code)
- [Ripgrep Documentation](https://github.com/BurntSushi/ripgrep)
- [PostgreSQL Performance Tuning](https://wiki.postgresql.org/wiki/Tuning_Your_PostgreSQL_Server)
- [Docker Best Practices](https://docs.docker.com/develop/dev-best-practices/)

---

*These optimizations are based on Claude Code's performance patterns and adapted for the Investment Analysis Platform's specific requirements.*