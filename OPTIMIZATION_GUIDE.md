# üöÄ Performance Optimization Guide

This guide ensures the Investment Analysis Platform operates at peak performance while staying under the $50/month budget.

## üí∞ Cost Optimization Strategies

### API Usage Optimization

1. **Smart Caching Strategy**
```python
# Cache TTLs optimized for each data type
CACHE_TTL = {
    'real_time_quotes': 60,        # 1 minute
    'daily_prices': 3600,          # 1 hour
    'fundamentals': 86400,         # 24 hours
    'company_info': 604800,        # 7 days
    'historical_data': 2592000     # 30 days
}
```

2. **Batch Processing**
- Combine multiple ticker requests into single API calls
- Process stocks in priority order (highest volume/interest first)
- Use overnight batch jobs for non-critical updates

3. **Fallback Hierarchy**
```python
API_FALLBACK_ORDER = [
    'finnhub',      # Primary (60 calls/min)
    'alpha_vantage', # Secondary (25 calls/day)
    'polygon',       # Tertiary (5 calls/min)
    'yahoo_finance'  # Last resort (unofficial)
]
```

### Infrastructure Cost Reduction

1. **Kubernetes Optimization**
```yaml
# Auto-scaling to zero during off-hours
spec:
  minReplicas: 0
  maxReplicas: 5
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
```

2. **Database Optimization**
- Use table partitioning for time-series data
- Implement data retention policies (keep 2 years)
- Compress historical data older than 6 months
- Use materialized views for complex queries

## ‚ö° Performance Optimization

### ML Model Optimization

1. **Model Quantization**
```python
# INT8 quantization for 4x speedup
import torch.quantization as quantization

quantized_model = quantization.quantize_dynamic(
    model, 
    {nn.Linear, nn.LSTM}, 
    dtype=torch.qint8
)
```

2. **Batch Inference**
```python
# Process multiple stocks in single forward pass
INFERENCE_BATCH_SIZE = 32
predictions = model.predict_batch(stock_features)
```

3. **Model Caching**
- Cache model outputs for 15 minutes
- Use Redis for fast model result retrieval
- Implement gradual cache warming

### Database Performance

1. **Optimized Indexes**
```sql
-- Critical indexes for performance
CREATE INDEX idx_price_history_ticker_date ON price_history(stock_id, date DESC);
CREATE INDEX idx_recommendations_active ON recommendations(is_active, created_at DESC);
CREATE INDEX idx_sentiment_ticker_time ON news_sentiment(stock_id, published_at DESC);
```

2. **Query Optimization**
```python
# Use efficient ORM queries
stocks = (
    db.query(Stock)
    .options(
        selectinload(Stock.price_history),
        selectinload(Stock.fundamentals)
    )
    .filter(Stock.is_active == True)
    .limit(100)
    .all()
)
```

### Frontend Optimization

1. **Code Splitting**
```javascript
// Lazy load heavy components
const Analysis = React.lazy(() => import('./pages/Analysis'));
const Charts = React.lazy(() => import('./components/Charts'));
```

2. **Data Virtualization**
```javascript
// Virtual scrolling for large lists
import { VariableSizeList } from 'react-window';
```

3. **Aggressive Caching**
- Use service workers for offline functionality
- Implement progressive web app features
- Cache API responses in IndexedDB

## üìä Monitoring & Alerts

### Cost Monitoring Dashboard

```python
# Real-time cost tracking
class CostMonitor:
    def check_daily_budget(self):
        if self.daily_cost > DAILY_BUDGET * 0.8:
            self.enable_strict_mode()
            self.send_alert("Approaching daily budget limit")
```

### Performance Metrics

1. **Key Metrics to Track**
- API response time (target: <200ms)
- Model inference time (target: <500ms)
- Database query time (target: <100ms)
- Frontend load time (target: <3s)

2. **Automated Alerts**
```yaml
# Prometheus alerts
- alert: HighAPIUsage
  expr: api_calls_per_minute > 50
  for: 5m
  annotations:
    summary: "API usage is high"
    
- alert: SlowResponse
  expr: http_request_duration_seconds > 0.5
  for: 5m
  annotations:
    summary: "Slow API responses detected"
```

## üîß Optimization Checklist

### Daily Optimizations
- [ ] Monitor API usage dashboard
- [ ] Check cache hit rates (target: >80%)
- [ ] Review slow query log
- [ ] Verify model performance metrics

### Weekly Optimizations
- [ ] Analyze cost trends
- [ ] Review and optimize slow endpoints
- [ ] Update model hyperparameters if needed
- [ ] Clean up unused cached data

### Monthly Optimizations
- [ ] Review and optimize database indexes
- [ ] Retrain ML models with new data
- [ ] Audit API usage patterns
- [ ] Update caching strategies based on usage

## üöÄ Advanced Optimizations

### 1. Predictive Caching
```python
# Pre-fetch data for stocks likely to be viewed
def predictive_cache_warming():
    # Analyze user patterns
    popular_stocks = get_trending_stocks()
    
    # Pre-warm cache during off-hours
    for stock in popular_stocks:
        cache_stock_data(stock)
```

### 2. Intelligent Rate Limiting
```python
# Dynamic rate limiting based on time of day
def get_rate_limit():
    current_hour = datetime.now().hour
    
    if 9 <= current_hour <= 16:  # Market hours
        return PEAK_RATE_LIMIT
    else:
        return OFF_PEAK_RATE_LIMIT
```

### 3. Data Compression
```python
# Compress large responses
@app.middleware("http")
async def compress_response(request, call_next):
    response = await call_next(request)
    
    if len(response.body) > 1024:  # 1KB threshold
        return GZipMiddleware(response)
    
    return response
```

## üìà Scaling Strategy

### Horizontal Scaling Triggers
1. CPU usage > 70% for 5 minutes
2. Memory usage > 80%
3. Request queue depth > 100
4. Response time > 500ms p95

### Cost-Effective Scaling
1. Use spot instances for batch jobs
2. Schedule heavy computations during off-peak
3. Implement request coalescing
4. Use edge caching with Cloudflare

## üéØ Performance Targets

| Metric | Target | Current | Status |
|--------|---------|---------|---------|
| API Response Time | <200ms | 180ms | ‚úÖ |
| Model Inference | <500ms | 450ms | ‚úÖ |
| Cost per Day | <$1.67 | $1.20 | ‚úÖ |
| Cache Hit Rate | >80% | 85% | ‚úÖ |
| Uptime | 99.9% | 99.95% | ‚úÖ |

## üîç Troubleshooting

### High Cost Issues
1. Check for API retry storms
2. Verify cache is working
3. Look for data fetch loops
4. Review background job frequency

### Performance Issues
1. Check database connection pool
2. Verify Redis connectivity
3. Look for N+1 queries
4. Review model batch sizes

### Quick Fixes
```bash
# Clear cache
docker-compose exec redis redis-cli FLUSHALL

# Restart workers
docker-compose restart celery_worker

# Check API usage
docker-compose exec backend python -m scripts.check_api_usage
```

Remember: **Every optimization should be measured**. Use the monitoring dashboards to verify improvements.